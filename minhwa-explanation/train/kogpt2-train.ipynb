{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakyommii/MinhwaProject/blob/main/minhwa-explanation/train/kogpt2-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KoGPT2"
      ],
      "metadata": {
        "id": "-YOeDwDspv2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8_hhOGSZGmkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "omJcVJ5rTUIq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ZVHIOKpnKR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "HsvrYLjFprM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset"
      ],
      "metadata": {
        "id": "WMajy_Txp2h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# CSV 파일 로드\n",
        "csv_file_path = \"/content/drive/MyDrive/seol/datasets/kor_data-fin.csv\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# 텍스트 데이터 추출\n",
        "keyword_col = df['keyword']\n",
        "exp_col = df['explanation']\n",
        "# 다른 열도 필요한 만큼 추가\n",
        "\n",
        "# 추출된 텍스트 데이터 리스트를 리스트로 변환\n",
        "kwd_lst = keyword_col.tolist()\n",
        "exp_lst=exp_col.tolist()\n",
        "\n",
        "# 파인튜닝에 사용할 데이터 생성\n",
        "train_texts = []\n",
        "for i in range(len(kwd_lst)):\n",
        "    combined_text = f\"{kwd_lst[i]} | {exp_lst[i]}\"  # 필요에 따라 조합\n",
        "    train_texts.append(combined_text)"
      ],
      "metadata": {
        "id": "SmcK1-3oFner"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fine-tuning"
      ],
      "metadata": {
        "id": "2RK7R2LEptEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from fastai.text.all import *\n",
        "import fastai\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "7qSPXiM0F4GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuned 모델 로드"
      ],
      "metadata": {
        "id": "EVyTCfpHWpBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# KoGPT2 모델 불러오기\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# KoGPT2 토크나이저 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                                    bos_token='</s>',\n",
        "                                                    eos_token='</s>',\n",
        "                                                    unk_token='<unk>',\n",
        "                                                    pad_token='<pad>',\n",
        "                                                    mask_token='<mask>')\n"
      ],
      "metadata": {
        "id": "r6_QtdqQFOaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 로드 & Fine-tuning"
      ],
      "metadata": {
        "id": "pkIe3iVzWsmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, tokenizer, text_list, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_list = text_list\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.text_list[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        inputs = {\n",
        "            'input_ids': encoding['input_ids'],\n",
        "            'attention_mask': encoding['attention_mask']  # attention_mask 추가\n",
        "        }\n",
        "        return inputs\n",
        "\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델과 토크나이저 로드\n",
        "model.to(device)\n",
        "\n",
        "# 파인튜닝을 위한 데이터 준비\n",
        "train_dataset = MyDataset(tokenizer, train_texts)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# 옵티마이저 및 스케줄러 설정\n",
        "num_epochs = 300\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=100, num_training_steps=len(train_dataloader) * num_epochs\n",
        ")\n",
        "\n",
        "# 초기 손실을 큰 값으로 설정\n",
        "best_loss = float(\"inf\")\n",
        "\n",
        "# 파인튜닝 하기\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in train_dataloader:\n",
        "      inputs = {\n",
        "          'input_ids': batch['input_ids'].to(device),\n",
        "          'attention_mask': batch['attention_mask'].to(device)\n",
        "      }\n",
        "      outputs = model(**inputs, labels=inputs['input_ids'])  # labels도 input_ids와 동일하게 설정\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    # 평균 손실 계산\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}\")\n",
        "\n",
        "    # 현재 모델의 손실이 이전 모델보다 낮으면 모델 저장\n",
        "    if average_loss < best_loss:\n",
        "        best_loss = average_loss\n",
        "        model.save_pretrained(\"/content/drive/MyDrive/seol/ckpt/kogpt2-test\")\n",
        "        tokenizer.save_pretrained(\"/content/drive/MyDrive/seol/ckpt/kogpt2-test\")\n"
      ],
      "metadata": {
        "id": "XVnessWypuuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텍스트 생성 테스트"
      ],
      "metadata": {
        "id": "urQkjYyLVYTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"/content/drive/MyDrive/seol/ckpt/kogpt2-fin\",\n",
        "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "  pad_token='<pad>', mask_token='<mask>') # 토크나이저\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"/content/drive/MyDrive/seol/ckpt/kogpt2-fin\")  # 모델 불러오기\n",
        "\n",
        "prompt = \"호랑이, 까치\" ## 입력 텍스트\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# 텍스트 생성\n",
        "output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
        "\n",
        "# 생성된 텍스트 출력\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "3PZQS4FWGLir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 후처리"
      ],
      "metadata": {
        "id": "FhqXfBftGiXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_after_char(s, char):\n",
        "    # 문자열을 특정 문자 기준으로 분할\n",
        "    parts = s.split(char)\n",
        "    # 첫 번째 부분만 반환\n",
        "    return parts[0]"
      ],
      "metadata": {
        "id": "JvHnTN-KGhZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val=generated_text\n",
        "val_new = remove_after_char(val, '”')\n",
        "generated_text=val_new"
      ],
      "metadata": {
        "id": "YeV7Ig1CGnJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwd=prompt.split(',')"
      ],
      "metadata": {
        "id": "uZ4fi8QTJedE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defaultdict를 int로 초기화합니다. 새 키에 대한 기본값은 0이 됩니다.\n",
        "key_map = defaultdict(int)\n",
        "\n",
        "# 각 요소에 대해 카운트를 증가시킵니다.\n",
        "for i in range(0,len(kwd)):\n",
        "\n",
        "  if i>0: k=kwd[i][1:]\n",
        "  else: k=kwd[i]\n",
        "\n",
        "  kr=k.split()[-1]\n",
        "  key_map[kr] += 1"
      ],
      "metadata": {
        "id": "mvp4ZV4VKvkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 민화 장르 분류\n",
        "gen=''\n",
        "\n",
        "# 모란 개수\n",
        "mc = key_map['모란']\n",
        "\n",
        "if(key_map['호랑이']>0): gen='호작도'\n",
        "elif(key_map['학']>0): gen='송학도'\n",
        "elif(key_map['봉황']>0): gen='봉황도'\n",
        "elif(key_map['연꽃']>0):\n",
        "  # 모란 없음\n",
        "  if(mc==0 or mc<key_map['연꽃']): gen='연화도'\n",
        "  # 모란 있음 -> 개수 비교\n",
        "  else: gen='모란도'\n",
        "elif(mc>0): gen='모란도'\n",
        "else: gen='화조도'"
      ],
      "metadata": {
        "id": "VPyEa0ulHd4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rep=gen+\"입니다\"\n",
        "val=generated_text\n",
        "val_new = val.replace('모란도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new\n",
        "\n",
        "val=generated_text\n",
        "val_new = val.replace('호작도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new\n",
        "\n",
        "val=generated_text\n",
        "val_new = val.replace('송학도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new\n",
        "\n",
        "val=generated_text\n",
        "val_new = val.replace('봉황도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new\n",
        "\n",
        "val=generated_text\n",
        "val_new = val.replace('연화도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new\n",
        "\n",
        "val=generated_text\n",
        "val_new = val.replace('화조도입니다', rep) # 바꿀 텍스트와 대체할 텍스트\n",
        "generated_text=val_new"
      ],
      "metadata": {
        "id": "zd2E8LdxOYKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "id": "jXEzfjcNPRRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}